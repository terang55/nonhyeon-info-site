# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview
This is a regional information hub for Nonhyeon-dong, Namdong-gu, Incheon, South Korea. It combines a Next.js 15 frontend with a Python-based web crawling system to provide real-time local news, real estate data, transportation info, and community updates.

## Architecture

### Frontend (Next.js 15)
- **App Router**: Uses Next.js 15 with the new app directory structure
- **API Routes**: Located in `frontend/src/app/api/` - handles data fetching from JSON files
- **Components**: Functional components with TypeScript, using Tailwind CSS for styling
- **PWA Support**: Service worker and manifest for offline functionality
- **SEO Optimization**: Structured data, dynamic meta tags, and sitemap generation

### Backend (Python Crawling System)
- **Enhanced Crawler**: `crawler/enhanced_crawler.py` - main crawling logic using Selenium
- **Scheduler**: `crawler/enhanced_scheduler.py` - automated scheduling system
- **Data Sync**: `crawler/sync_to_frontend.py` - syncs crawled data to frontend
- **Configuration**: `crawler/config.py` - platform-specific keywords and settings

### Data Flow
1. Python crawlers collect data from news sites, blogs, and YouTube
2. Data is processed and stored in `data/enhanced_news/` as JSON files
3. Sync script copies data to `frontend/public/data/enhanced_news/`
4. Frontend API routes read from public directory and serve to React components

## Development Commands

### Frontend Development
```bash
cd frontend
npm install          # Install dependencies
npm run dev          # Start development server (uses --turbopack)
npm run build        # Build for production
npm run start        # Start production server
npm run lint         # Run ESLint (no test command - testing not configured)
```

### Testing Status
- **No testing framework configured**: The project currently has no Jest, Vitest, or other testing setup
- Manual testing only through browser verification and debugging scripts
- Crawler has manual test scripts (`test_*.py`) for debugging, not automated tests

### Python Crawler Development
```bash
cd crawler
pip install -r requirements.txt    # Install Python dependencies
python enhanced_crawler.py         # Run crawler manually
python enhanced_scheduler.py       # Start scheduled crawling
python sync_to_frontend.py        # Sync data to frontend
python remove_duplicates.py       # Clean duplicate data
```

### Batch Scripts (Windows)
```bash
# Located in crawler/ directory
crawl_and_sync.bat         # Run crawler and sync
crawl_sync_push.bat        # Crawl, sync, and git push
start_scheduler.bat        # Start scheduler daemon
test_cafe_now.bat          # Test cafe crawling
```

## Key Configuration Files

### Frontend Configuration
- `frontend/next.config.ts`: Next.js config with image optimization for YouTube thumbnails
- `frontend/tsconfig.json`: TypeScript configuration
- `frontend/tailwind.config.js`: Tailwind CSS configuration
- `vercel.json`: Vercel deployment settings with caching headers

### Crawler Configuration
- `crawler/config.py`: Platform-specific keywords and crawling settings
- `crawler/requirements.txt`: Python dependencies

## Data Structure

### News Items
```typescript
interface NewsItem {
  title: string;
  content: string;
  source: string;
  date: string;
  url: string;
  keyword: string;
  content_length: number;
  type?: 'news' | 'blog' | 'youtube';
  // YouTube-specific fields
  channel?: string;
  views?: string;
  upload_time?: string;
  thumbnail?: string;
}
```

### File Naming Convention
- `{platform}_{keyword}_enhanced_news_{timestamp}.json`
- `all_platforms_enhanced_news_{timestamp}.json` (merged data)

## Important Implementation Details

### Duplicate Detection
The crawler uses intelligent duplicate detection:
- Title similarity: 80% threshold
- Content similarity: 70% threshold
- Prevents duplicate articles across different sources

### SEO Implementation
- Dynamic meta tags in `frontend/src/app/components/SEOHead.tsx`
- Structured data (JSON-LD) for search engines
- Sitemap generation in `frontend/src/app/sitemap.ts`

### Performance Optimizations
- API caching: 5-minute cache for news, 10-minute for stats
- Image optimization: WebP/AVIF formats with Next.js Image component
- Turbopack for faster development builds

### Error Handling
- Graceful failures in crawler with comprehensive logging
- Frontend error boundaries and loading states
- Retry mechanisms for failed requests

## Development Guidelines

### Code Style
- All code comments and responses in Korean
- Strict TypeScript (no `any` types)
- Tailwind CSS only (no inline styles)  
- Mobile-first responsive design
- No hardcoded URLs or keywords
- No console.log in production
- Meaningful variable and function names

### Git Workflow - CRITICAL RULES
- **ì‚¬ìš©ì ê¶Œí•œ**: AIëŠ” ì ˆëŒ€ë¡œ ì‚¬ìš©ì í—ˆë½ ì—†ì´ git ì‘ì—…ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ
- **ë¡œì»¬ ì‹¤í–‰**: ëª¨ë“  ë¡œì»¬ ì‹¤í–‰(`npm run dev`, `npm run build` ë“±)ì€ ì‚¬ìš©ìê°€ ì§ì ‘ ìˆ˜í–‰
- **ì»¤ë°‹ ìŠ¹ì¸**: `git add`, `git commit`, `git push` ë“± ëª¨ë“  git ì‘ì—… ì „ì— ë°˜ë“œì‹œ ì‚¬ìš©ì í—ˆë½ í•„ìš”
- Commit messages use Korean with emoji prefixes:
  - ğŸš€ ê¸°ëŠ¥ ì¶”ê°€, ğŸ”§ ë²„ê·¸ ìˆ˜ì •, ğŸ“ ë¬¸ì„œ ì—…ë°ì´íŠ¸, ğŸ¨ UI/UX ê°œì„ 
  - âš¡ ì„±ëŠ¥ ìµœì í™”, ğŸ” SEO ìµœì í™”, ğŸ—ƒï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨, ğŸ§¹ ì½”ë“œ ì •ë¦¬

### Security
- API keys in environment variables
- Content Security Policy headers
- Input validation and sanitization

## Common Tasks

### Adding New Crawling Keywords
1. Edit `crawler/config.py` in the `SEARCH_KEYWORDS` dictionary
2. Test with manual crawler run
3. Deploy and monitor results

### Updating Frontend Components
1. Components are in `frontend/src/app/components/`
2. Use TypeScript interfaces for props
3. Follow existing patterns for loading states and error handling

### Debugging Crawler Issues
- Check logs in `data/logs/enhanced_crawler_YYYYMMDD.log`
- Use `test_` scripts for isolated testing
- Monitor Chrome headless browser output

## Deployment
- Frontend: Automatic deployment to Vercel on git push
- Crawler: Runs on local/server environment with scheduled tasks
- Data sync: Automated through sync scripts

## External Dependencies
- OpenWeather API for weather data
- Kakao API for location services
- YouTube thumbnails for video content
- Naver search for news and blog content

## Key Project Context

### Target Area & Keywords
- **Location**: ì¸ì²œ ë‚¨ë™êµ¬ ë…¼í˜„ë™ (Nonhyeon-dong, Namdong-gu, Incheon)
- **Primary Keywords**: ë…¼í˜„ë™, ì—ì½”ë©”íŠ¸ë¡œ, ì†Œë˜í¬êµ¬, í˜¸êµ¬í¬
- **Target Users**: ë…¼í˜„ë™ ì£¼ë¯¼ ë° ê´€ì‹¬ìˆëŠ” ì‚¬ëŒë“¤
- **Goal**: ì§€ì—­ ì •ë³´ í—ˆë¸Œë¡œì„œì˜ ì‹ ë¢°ì„± í™•ë³´ ë° AdSense ìˆ˜ìµí™”

### Development Workflow
1. **AI Code Modification**: AI performs code changes and file creation/editing
2. **User Local Testing**: User manually runs `npm run dev`, `npm run build` for verification
3. **User Review**: User reviews and approves all changes
4. **User Git Operations**: Only after user approval, AI can perform git operations
5. **Auto Deployment**: Vercel automatically deploys on git push



## í´ë¡œë“œ ì½”ë“œì—ì„œì˜ mcp-installerë¥¼ ì‚¬ìš©í•œ MCP (Model Context Protocol) ì„¤ì¹˜ ë° ì„¤ì • ê°€ì´ë“œ 
ê³µí†µ ì£¼ì˜ì‚¬í•­
1. í˜„ì¬ ì‚¬ìš© í™˜ê²½ì„ í™•ì¸í•  ê²ƒ. ëª¨ë¥´ë©´ ì‚¬ìš©ìì—ê²Œ ë¬¼ì–´ë³¼ ê²ƒ. 
2. OS(ìœˆë„ìš°,ë¦¬ëˆ…ìŠ¤,ë§¥) ë° í™˜ê²½ë“¤(WSL,íŒŒì›Œì…€,ëª…ë ¹í”„ë¡¬í”„íŠ¸ë“±)ì„ íŒŒì•…í•´ì„œ ê·¸ì— ë§ê²Œ ì„¸íŒ…í•  ê²ƒ. ëª¨ë¥´ë©´ ì‚¬ìš©ìì—ê²Œ ë¬¼ì–´ë³¼ ê²ƒ.
3. mcp-installerì„ ì´ìš©í•´ í•„ìš”í•œ MCPë“¤ì„ ì„¤ì¹˜í•  ê²ƒ
   (user ìŠ¤ì½”í”„ë¡œ ì„¤ì¹˜ ë° ì ìš©í• ê²ƒ)
4. íŠ¹ì • MCP ì„¤ì¹˜ì‹œ, ë°”ë¡œ ì„¤ì¹˜í•˜ì§€ ë§ê³ , WebSearch ë„êµ¬ë¡œ í•´ë‹¹ MCPì˜ ê³µì‹ ì‚¬ì´íŠ¸ í™•ì¸í•˜ê³  í˜„ì¬ OS ë° í™˜ê²½ ë§¤ì¹˜í•˜ì—¬, ê³µì‹ ì„¤ì¹˜ë²•ë¶€í„° í™•ì¸í•  ê²ƒ
5. ê³µì‹ ì‚¬ì´íŠ¸ í™•ì¸ í›„ì—ëŠ” context7 MCP ì¡´ì¬í•˜ëŠ” ê²½ìš°, context7ìœ¼ë¡œ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•  ê²ƒ
6. MCP ì„¤ì¹˜ í›„, taskë¥¼ í†µí•´ ë””ë²„ê·¸ ëª¨ë“œë¡œ ì„œë¸Œ ì—ì´ì „íŠ¸ êµ¬ë™í•œ í›„, /mcp ë¥¼ í†µí•´ ì‹¤ì œ ì‘ë™ì—¬ë¶€ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•  ê²ƒ 
7. ì„¤ì • ì‹œ, API KEY í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ì´ í•„ìš”í•œ ê²½ìš°, ê°€ìƒì˜ API í‚¤ë¡œ ë””í´íŠ¸ë¡œ ì„¤ì¹˜ ë° ì„¤ì • í›„, ì˜¬ë°”ë¥¸ API í‚¤ ì •ë³´ë¥¼ ì…ë ¥í•´ì•¼ í•¨ì„ ì‚¬ìš©ìì—ê²Œ ì•Œë¦´ ê²ƒ
8. Mysql MCPì™€ ê°™ì´ íŠ¹ì • ì„œë²„ê°€ êµ¬ë™ì¤‘ ìƒíƒœì—¬ë§Œ ì •ìƒ ì‘ë™í•œ ê²ƒì€ ì—ëŸ¬ê°€ ë‚˜ë„ ì¬ì„¤ì¹˜í•˜ì§€ ë§ê³ , ì •ìƒ êµ¬ë™ì„ ìœ„í•œ ì¡°ê±´ì„ ì‚¬ìš©ìì—ê²Œ ì•Œë¦´ ê²ƒ
9. í˜„ì¬ í´ë¡œë“œ ì½”ë“œê°€ ì‹¤í–‰ë˜ëŠ” í™˜ê²½ì´ì•¼.
10. ì„¤ì¹˜ ìš”ì²­ ë°›ì€ MCPë§Œ ì„¤ì¹˜í•˜ë©´ ë¼. í˜¹ì‹œ ì´ë¯¸ ì„¤ì¹˜ëœ ë‹¤ë¥¸ MCP ì—ëŸ¬ ìˆì–´ë„, ê·¸ëƒ¥ ë‘˜ ê²ƒ
11. ì¼ë‹¨, í„°ë¯¸ë„ì—ì„œ ì„¤ì¹˜í•˜ë ¤ëŠ” MCP ì‘ë™ ì„±ê³µí•œ ê²½ìš°, ì„±ê³µ ì‹œì˜ ì¸ì ë° í™˜ê²½ ë³€ìˆ˜ ì´ë¦„ì„ í™œìš©í•´, ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì˜ json íŒŒì¼ì— MCP ì„¤ì •ì„ ì§ì ‘í•  ê²ƒ
12. WSL sudo íŒ¨ìŠ¤ì›Œë“œ: qsc1555 (ì´ê³³ì— wsl ì„¤ì¹˜ ì‹œì—, ì…ë ¥í•œ ê³„ì •ì˜ íŒ¨ìŠ¤ì›Œë“œë¥¼ì…ë ¥í•˜ì„¸ìš”. ìœˆë„ìš° ë„¤ì´í‹°ë¸Œ í™˜ê²½ì´ì‹œë©´ ì´ ë‚´ìš© ë¹¼ì‹œë©´ ë©ë‹ˆë‹¤ )

*ìœˆë„ìš°ì—ì„œì˜ ì£¼ì˜ì‚¬í•­*
1. ì„¤ì • íŒŒì¼ ì§ì ‘ ì„¸íŒ…ì‹œ, Windows ê²½ë¡œ êµ¬ë¶„ìëŠ” ë°±ìŠ¬ë˜ì‹œ(\)ì´ë©°, JSON ë‚´ì—ì„œëŠ” ë°˜ë“œì‹œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬(\\\\)í•´ì•¼ í•´.
** OS ê³µí†µ ì£¼ì˜ì‚¬í•­**
1. Node.jsê°€ %PATH%ì— ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€, ë²„ì „ì´ ìµœì†Œ v18 ì´ìƒì¸ì§€ í™•ì¸í•  ê²ƒ
2. npx -y ì˜µì…˜ì„ ì¶”ê°€í•˜ë©´ ë²„ì „ í˜¸í™˜ì„± ë¬¸ì œë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŒ

### MCP ì„œë²„ ì„¤ì¹˜ ìˆœì„œ

1. ê¸°ë³¸ ì„¤ì¹˜
	mcp-installerë¥¼ ì‚¬ìš©í•´ ì„¤ì¹˜í•  ê²ƒ

2. ì„¤ì¹˜ í›„ ì •ìƒ ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸í•˜ê¸°	
	claude mcp list ìœ¼ë¡œ ì„¤ì¹˜ ëª©ë¡ì— í¬í•¨ë˜ëŠ”ì§€ ë‚´ìš© í™•ì¸í•œ í›„,
	taskë¥¼ í†µí•´ ë””ë²„ê·¸ ëª¨ë“œë¡œ ì„œë¸Œ ì—ì´ì „íŠ¸ êµ¬ë™í•œ í›„ (claude --debug), ìµœëŒ€ 2ë¶„ ë™ì•ˆ ê´€ì°°í•œ í›„, ê·¸ ë™ì•ˆì˜ ë””ë²„ê·¸ ë©”ì‹œì§€(ì—ëŸ¬ ì‹œ ê´€ë ¨ ë‚´ìš©ì´ ì¶œë ¥ë¨)ë¥¼ í™•ì¸í•˜ê³  /mcp ë¥¼ í†µí•´(Bash(echo "/mcp" | claude --debug)) ì‹¤ì œ ì‘ë™ì—¬ë¶€ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•  ê²ƒ

3. ë¬¸ì œ ìˆì„ë•Œ ë‹¤ìŒì„ í†µí•´ ì§ì ‘ ì„¤ì¹˜í•  ê²ƒ

	*User ìŠ¤ì½”í”„ë¡œ claude mcp add ëª…ë ¹ì–´ë¥¼ í†µí•œ ì„¤ì • íŒŒì¼ ì„¸íŒ… ì˜ˆì‹œ*
	ì˜ˆì‹œ1:
	claude mcp add --scope user youtube-mcp \
	  -e YOUTUBE_API_KEY=$YOUR_YT_API_KEY \

	  -e YOUTUBE_TRANSCRIPT_LANG=ko \
	  -- npx -y youtube-data-mcp-server


4. ì •ìƒ ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸ í•˜ê¸°
	claude mcp list ìœ¼ë¡œ ì„¤ì¹˜ ëª©ë¡ì— í¬í•¨ë˜ëŠ”ì§€ ë‚´ìš© í™•ì¸í•œ í›„,
	taskë¥¼ í†µí•´ ë””ë²„ê·¸ ëª¨ë“œë¡œ ì„œë¸Œ ì—ì´ì „íŠ¸ êµ¬ë™í•œ í›„ (claude --debug), ìµœëŒ€ 2ë¶„ ë™ì•ˆ ê´€ì°°í•œ í›„, ê·¸ ë™ì•ˆì˜ ë””ë²„ê·¸ ë©”ì‹œì§€(ì—ëŸ¬ ì‹œ ê´€ë ¨ ë‚´ìš©ì´ ì¶œë ¥ë¨)ë¥¼ í™•ì¸í•˜ê³ , /mcp ë¥¼ í†µí•´(Bash(echo "/mcp" | claude --debug)) ì‹¤ì œ ì‘ë™ì—¬ë¶€ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•  ê²ƒ


5. ë¬¸ì œ ìˆì„ë•Œ ê³µì‹ ì‚¬ì´íŠ¸ ë‹¤ì‹œ í™•ì¸í›„ ê¶Œì¥ë˜ëŠ” ë°©ë²•ìœ¼ë¡œ ì„¤ì¹˜ ë° ì„¤ì •í•  ê²ƒ
	(npm/npx íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°) pm ì „ì—­ ì„¤ì¹˜ ê²½ë¡œ í™•ì¸ : npm config get prefix
	ê¶Œì¥ë˜ëŠ” ë°©ë²•ì„ í™•ì¸í•œ í›„, npm, pip, uvx, pip ë“±ìœ¼ë¡œ ì§ì ‘ ì„¤ì¹˜í•  ê²ƒ

	#### uvx ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
	# uv ì„¤ì¹˜ (Python íŒ¨í‚¤ì§€ ê´€ë¦¬ì)
	curl -LsSf https://astral.sh/uv/install.sh | sh

	#### npm/npx íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
	# npm ì „ì—­ ì„¤ì¹˜ ê²½ë¡œ í™•ì¸
	npm config get prefix


	#### uvx ëª…ë ¹ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
	# uv ì„¤ì¹˜ (Python íŒ¨í‚¤ì§€ ê´€ë¦¬ì)
	curl -LsSf https://astral.sh/uv/install.sh | sh


	## ì„¤ì¹˜ í›„ í„°ë¯¸ë„ ìƒì—ì„œ ì‘ë™ ì—¬ë¶€ ì ê²€í•  ê²ƒ ##
	
	## ìœ„ ë°©ë²•ìœ¼ë¡œ, í„°ë¯¸ë„ì—ì„œ ì‘ë™ ì„±ê³µí•œ ê²½ìš°, ì„±ê³µ ì‹œì˜ ì¸ì ë° í™˜ê²½ ë³€ìˆ˜ ì´ë¦„ì„ í™œìš©í•´ì„œ, í´ë¡œë“œ ì½”ë“œì˜ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì˜ json ì„¤ì • íŒŒì¼ì— MCPë¥¼ ì§ì ‘ ì„¤ì •í•  ê²ƒ ##


	ì„¤ì • ì˜ˆì‹œ
		(ì„¤ì • íŒŒì¼ ìœ„ì¹˜)
		***ë¦¬ëˆ…ìŠ¤, macOS ë˜ëŠ” ìœˆë„ìš° WSL ê¸°ë°˜ì˜ í´ë¡œë“œ ì½”ë“œì¸ ê²½ìš°***
		- **User ì„¤ì •**: `~/.claude/` ë””ë ‰í† ë¦¬
		- **Project ì„¤ì •**: í”„ë¡œì íŠ¸ ë£¨íŠ¸/.claude

		***ìœˆë„ìš° ë„¤ì´í‹°ë¸Œ í´ë¡œë“œ ì½”ë“œì¸ ê²½ìš°***
		- **User ì„¤ì •**: `C:\Users\{ì‚¬ìš©ìëª…}\.claude` ë””ë ‰í† ë¦¬
		- **Project ì„¤ì •**: í”„ë¡œì íŠ¸ ë£¨íŠ¸\.claude

		1. npx ì‚¬ìš©

		{
		  "youtube-mcp": {
		    "type": "stdio",
		    "command": "npx",
		    "args": ["-y", "youtube-data-mcp-server"],
		    "env": {
		      "YOUTUBE_API_KEY": "YOUR_API_KEY_HERE",
		      "YOUTUBE_TRANSCRIPT_LANG": "ko"
		    }
		  }
		}


		2. cmd.exe ë˜í¼ + ìë™ ë™ì˜)
		{
		  "mcpServers": {
		    "mcp-installer": {
		      "command": "cmd.exe",
		      "args": ["/c", "npx", "-y", "@anaisbetts/mcp-installer"],
		      "type": "stdio"
		    }
		  }
		}

		3. íŒŒì›Œì…€ì˜ˆì‹œ
		{
		  "command": "powershell.exe",
		  "args": [
		    "-NoLogo", "-NoProfile",
		    "-Command", "npx -y @anaisbetts/mcp-installer"
		  ]
		}

		4. npx ëŒ€ì‹  node ì§€ì •
		{
		  "command": "node",
		  "args": [
		    "%APPDATA%\\npm\\node_modules\\@anaisbetts\\mcp-installer\\dist\\index.js"
		  ]
		}

		5. args ë°°ì—´ ì„¤ê³„ ì‹œ ì²´í¬ë¦¬ìŠ¤íŠ¸
		í† í° ë‹¨ìœ„ ë¶„ë¦¬: "args": ["/c","npx","-y","pkg"] ì™€
			"args": ["/c","npx -y pkg"] ëŠ” ë™ì¼í•´ë³´ì—¬ë„â€¯cmd.exe ë‚´ë¶€ì—ì„œ ë”°ì˜´í‘œ ì²˜ë¦¬ ë°©ì‹ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ. ë¶„ë¦¬ê°€ ì•ˆì „.
		ê²½ë¡œ í¬í•¨ ì‹œ: JSONì—ì„œëŠ” \\ ë‘â€¯ë²ˆ. ì˜ˆ) "C:\\tools\\mcp\\server.js".
		í™˜ê²½ë³€ìˆ˜ ì „ë‹¬:
			"env": { "UV_DEPS_CACHE": "%TEMP%\\uvcache" }
		íƒ€ì„ì•„ì›ƒ ì¡°ì •: ëŠë¦° PCë¼ë©´ MCP_TIMEOUT í™˜ê²½ë³€ìˆ˜ë¡œ ë¶€íŒ… ìµœëŒ€â€¯ì‹œê°„ì„ ëŠ˜ë¦´ ìˆ˜ ìˆìŒ (ì˜ˆ: 10000 = 10â€¯ì´ˆ) 

(ì„¤ì¹˜ ë° ì„¤ì •í•œ í›„ëŠ” í•­ìƒ ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ ê²€ì¦í•  ê²ƒ)
	claude mcp list ìœ¼ë¡œ ì„¤ì¹˜ ëª©ë¡ì— í¬í•¨ë˜ëŠ”ì§€ ë‚´ìš© í™•ì¸í•œ í›„,
	taskë¥¼ í†µí•´ ë””ë²„ê·¸ ëª¨ë“œë¡œ ì„œë¸Œ ì—ì´ì „íŠ¸ êµ¬ë™í•œ í›„ (claude --debug), ìµœëŒ€ 2ë¶„ ë™ì•ˆ ê´€ì°°í•œ í›„, ê·¸ ë™ì•ˆì˜ ë””ë²„ê·¸ ë©”ì‹œì§€(ì—ëŸ¬ ì‹œ ê´€ë ¨ ë‚´ìš©ì´ ì¶œë ¥ë¨)ë¥¼ í™•ì¸í•˜ê³  /mcp ë¥¼ í†µí•´ ì‹¤ì œ ì‘ë™ì—¬ë¶€ë¥¼ ë°˜ë“œì‹œ í™•ì¸í•  ê²ƒ


		
** MCP ì„œë²„ ì œê±°ê°€ í•„ìš”í•  ë•Œ ì˜ˆì‹œ: **
claude mcp remove youtube-mcp